from anthropic import Anthropic
from dotenv import load_dotenv
from pydantic import BaseModel, Field
import os
import time
import json
import pandas as pd

load_dotenv()

synthetic_model = os.getenv("DEFAULT_SYNTHETIC_MODEL", "claude-2")

class SyntheticDocs(BaseModel):
    """
    Synthetic documents generated by LLMs
    """

    docID: int = Field(
        ...,
        description="Unique identifier for the document",
    )
    content: str = Field(
        ...,
        description="Content of the synthetic document",
    )
    
def generate_synthetic_docs(
    industry: str,
    context: str,
    additional_prompt: str = "No other instructions",
    model: str = synthetic_model,
    starting_docID: int = 1,
    num_docs: int = 20,
    min_doc_length: int = 50,
    max_doc_length: int = 100,
) -> pd.DataFrame:
    """
    Generate synthetic docs using an LLM.

    Args:
        industry (str): Industry for which to generate documents.
        context (str): Context for the documents.
        additional_prompt (str): Any additional instructions to generate documents.
        model (str): The model to use for generation.
        starting_docID (int): Starting document ID for the generated documents.
        num_docs (int): Number of documents to generate.
        min_doc_length (int): Minimum no of tokens of each document.
        max_doc_length (int): Maximum no of tokens of each document.

    Returns:
        pd.DataFrame: Generated synthetic documents.
    """
    if num_docs*max_doc_length > 40000:
        raise ValueError(
            f"Cannot generate {num_docs} documents with a maximum length of {max_doc_length} tokens each. "
            f"Try generating in batches using the `starting_docID` parameter or reduce the number of documents or their length."
        )
    else:
        start = time.time()
        
        prompt = (
            f"Generate {num_docs} synthetic documents for the {industry} industry. "
            f"The documents should contain content related to the following context: {context}. "
            f"Additional instructions: {additional_prompt}. "
            f"Each document should be no shorter than {min_doc_length} and no longer than {max_doc_length} tokens."
            f"Do not include entities or specific names in the documents"
            f"Return the response as a list of JSON objects with the following format:\n"
            f"""
            The JSON objects should each have a 'docID' field numbered consecutively from {starting_docID} a
            and a 'content' field containing the generated document text.
            """
        )

        client = Anthropic()
        print(f"""
    Generating {num_docs} synthetic documents for the {industry} industry with the requested context using model {model}. 
    This usually takes about one second per document....
              """)
    
        response = []

        with client.messages.stream(
            max_tokens=64000,
            system="You are an expert in generating synthetic documents for various industries.",
            messages=[
                {"role": "user", "content": prompt},
                {"role": "assistant", "content": '[{"docID": ' + str(starting_docID) + ', "content": "'}
            ],
            model = model,
        ) as stream:
            for text in stream.text_stream:
                response.append(text)

        response = "".join(response)
        raw_response = '[{"docID": ' + str(starting_docID) + ', "content": "' + response
        docs = json.loads(raw_response)
        new_docs = []
        for i, doc in enumerate(docs):
            new_docs.append(SyntheticDocs(**doc))
        timer = time.time() - start
        print(f"Generated {len(new_docs)} synthetic documents successfully in {int(timer)} seconds.")
        return pd.DataFrame([res.model_dump() for res in new_docs])

    